**지능형 CCTV -- Poctv**

FaceNet, Yolo, DeepSORT를 활용한

출입 통제 및 이상 상황 감지 시스템

청년 AI Bigdata 아카데미

B1조

정찬영

김동현

노태현

정종훈

황다빈

**목차**

**1 프로젝트 개요**

**1.1 프로젝트 배경 및 목적**

**1.2 기존 서비스 및 연구**

**2 본론**

**2.1 전체 구조도**

**2.2 구현 과정**

> **2.2.1 이상상황 검출**
>
> **2.2.2 FaceNet**
>
> **2.2.3 deep sort를 이용한 동선파악**
>
> **2.2.4 통합 구현**

**3 결론**

**3.1 기대효과**

**3.2 한계점 및 발전 방향**

**4 조원 소개**

**5 참고 문헌**

**1 프로젝트 개요**

**1.1 프로젝트 배경 및 목적**

공공기관의 cctv는 매년 15% 안팎의 비율로 계속해서 늘어나고 있다. 또한
계속해서 cctv의 적용 범위는 넓어지고 있고 건물 및 대형 구조물에서
cctv데이터 관리의 필요성이 점점 중요해지고 있다.

울산 화재 사건, 포한 지진을 겪으면서, 건물 내 인원 파악의 필요성이
부각되고 있다. 공공기관이나 큰 건물의 cctv가 인원 파악 및 동선 파악을 할
수 있다면 화재나 지진같은 재해 현장에서 구조대가 효과적이고 안전하게
구조 작업을 진행 할 수 있는 여건이 된다.

또한 최근 COVID-19이 유행하고 있는 상황에서, 언택트 기반의 보안
기술이나, 동선 파악은 전염병 확산을 억제하는 데 큰 도움이 될것이다.
기존의 지문인식이나 다이얼 입력과 달리, 얼굴 인식을 통한 보안 솔루션은
접촉이 필요하지 않다.

또한 CCTV 만으로 누가 어떤 동선을 따라 이동했는지 파악할 수 있다면
코로나 환자 발생시, 동선이 겹치는 사람들을 관리해야 할 때 보다
효율적이고 안전하게 격리를 유도할 수 있게 된다.

**1.2 기존 서비스 및 연구**

a)  **온품**

![](media/image1.png){width="3.901042213473316in"
height="3.008911854768154in"}

화재 감지 CCTV와 네트워크 ID 기술을 이용하여, 화재 발생을 감지하고 건물
내 잔여 인원을 파악하는 기술. CCTV를 이용해 최적의 대피경로를 제시해주는
솔루션이다. 이와 비슷한 컨셉의 프로젝트이지만, 이 솔루션과 본
프로젝트와의 차별점은 여러가지 이상상황에 대응할 수 있다는 점, 오로지
CCTV만 이용한다는 점이다

![](media/image2.png){width="2.9531255468066493in"
height="2.8789884076990377in"}![](media/image3.png){width="3.276042213473316in"
height="1.9913199912510937in"}

\<YOLO를 이용한 폭력감지 시스템 연구\>

기존 연구에서 yolo를 이용하여 폭력상황을 감지하는 내용이 있었고, 이에
착안하여 폭력 외 다른 상황까지 yolo로 감지하고자 한다. 기존 yolo 학습은
한 이미지 내에서 labelling 하는 전처리 과정을 거쳐, 원하는 class를
찾아내는 것이다. 기존 yolo는 사물,동물에 사용되었다면, 본 연구는 상황을
찾아내는 학습이 될것이다.

**2 본론**

**2.1 전체 구조도**

![](media/image4.png){width="6.267716535433071in"
height="2.513888888888889in"}

입구에서 Facenet을 이용하여 출입 통제를 한다.

건물 내로 들어오면 2개 이상의 CCTV가 건물 내로 들어오는 사람들의 위치 및
이상상황 발생 여부를 계속해서 감지하여 서버에 저장한다.

서버에 저장된 데이터를 바탕으로 map에 표시한다.

**2.2 구현 과정**

**2.2.1 이상상황 검출**

전기수 프로젝트 PODORI의 경우, 캐글에서 violence non violence 영상
1000개씩을 16프레임씩 학습하고 검출해내는 3D convnet 모델이다.

![](media/image5.png){width="6.322916666666667in" height="3.16875in"}

![](media/image6.png){width="6.25in" height="5.177083333333333in"}

Violence 영상의 경우 개인이 싸움 장면을 직접 찍은 경우가 대부분이고,
매우 근접해서 찍는다던가, 흔들림이 매우 심한 등 정형화되어있지 않은
데이터이다.

Nonviolence 영상의 경우 violence가 없는 정상 상황이라기 보다는, 축구
동영상, 인터뷰 영상 등 역시 정형화되어 있지 않고 실제 cctv 시점과는 매우
다른 양상을 보인다.

전기수 프로젝트를 구현, 실험 해보았을 때, 진짜 폭력상황을 검출하기보다는
어두운 상황, 이미지의 급격한 변화를 폭력상황이라고 검출하는 양상을
보인다.

이와 같은 잘못된 학습의 원인은 정형화되어 있지 않은 데이터로
학습했기때문이라고 판단, 실제 데이터 제작 단체에서 제공되는 실신, 정상,
폭력상황 데이터를 활용하여 전기수 모델인 3D convnet 모델에 적용해
보았다. 기존 모델은 softmax layer에서 2개 상황(정상, 폭력상황)을
확률값으로 도출하여 판단한다. 이 모델을 수정하고 새롭게 추가된 데이터를
적용, 정상, 폭력상황, 실신, 기물파손 상황을 학습시켰다.

  ---------------------
  **Kaggle data set**
  **Nonvidolence**
  ---------------------

  ----------------------------------------------
  **AI hub '공항 이상행동 CCTV 영상' (frame)**
  **기물파손**
  **폭력**
  **실신**
  **총 13632 frames**
  ----------------------------------------------

![](media/image7.jpg){width="2.9626213910761154in"
height="1.6664337270341207in"}![](media/image8.jpg){width="2.9587423447069114in"
height="1.664251968503937in"}

**\<AI hub \'공항 이상행동 CCTV 영상\'\>**

총 13632 장의 사진들을 학습했다.그러나 학습을 여러가지 방법으로
시켜봐도, 실제 실험 상황에서는 제대로 판단을 해내지 못하는 문제가
있었다. 각 class의 확률이 데이터 량과 비례하게 나오면서, 거의 변화가
없었다.

![](media/image9.png){width="3.8177088801399823in"
height="2.898160542432196in"}

**\<전기수 모델 학습 결과 - 변화가 없다\>**

3D convnet이 cctv시점에서 상황을 파악하기에는 적절하지 않은 모델이라고
판단, yolo v5를 이용한 학습 방법을 시도하였다

먼저 labelling 툴을 이용하여 각 프레임 각 영역의 class를 부여하는 작업이
필요하다.

![](media/image10.png){width="3.9518044619422574in"
height="2.3471784776902886in"}

**\<labelImg.py 파일을 실행.\>**

데이터의 출처는 AI hub의 실신, 정상, 폭행 데이터와 실험환경에서의 촬용한
데이터를 훈련용으로 따로 분류한것까지 총 523장 사용하였다.

  ---------------------------------------------- -----
  **AI hub '공항 이상행동 CCTV 영상' (frame)**   
  **정상**                                       139
  **폭력**                                       239
  **실신**                                       97
  **자체 제작 학습용 영상**                      
  **실험영상**                                   48
  **총**                                         523
  ---------------------------------------------- -----

데이터 출처 :
[[https://aihub.or.kr/aidata/6258]{.ul}](https://aihub.or.kr/aidata/6258)

yolo v5의 훈련 결과는 다음과 같다

![](media/image11.png){width="6.166666666666667in"
height="3.0833333333333335in"}

![](media/image12.png){width="5.505208880139983in"
height="2.3502296587926508in"}

**\<학습 후 결과\>**

**2.2.2 FaceNet**

얼굴 인식 모델을 만들기 위해 OpenCV를 이용한 얼굴 인식을 진행해 보았다.
이미지를 넣으면 face만 잘라내 그 사진으로 학습시키는 모델을 만들어
보았지만 사진 수를 100개에서 5000개 가량 늘려도 정확도는 85를 넘지
못했고 학습시키지 않는 사람에 대한 정확도도 같이 올라가는 경향을 보여서
다른 얼굴 인식 시스템을 적용시킬 필요가 있다고 생각을 했다.

FaceNet은 Google 연구원이 개발한 얼굴 인식 시스템으로 임베딩을 통해
얼굴의 특성을 추출한 다음 얼굴 이미지에서 얼굴 유사성 척도와 얼마나
직접적으로 일치하는지 거리를 측정하는 밀집 유클리드 공간으로 매핑을 직접
학습한다. 즉 같은 얼굴 특성에 대한 벡터가 더 비슷해지고 다른 얼굴에 대한
벡터는 덜 비슷해질것이다.

따라서 우리는 이 얼굴 식별 시스템을 바탕으로 카메라가 다수의 사람을 인식
했을 때, 이 두 사람이 동일인물인지(Face-Verification),
누구인지(Recognition), 공통되는 사람들 찾기(Clustering)을 위한 통합
시스템을 제시한다. 이를 구현하기 위해 얼굴 유사성에 대한 수치를 계산해
이와 같은 기술을 적용한다.

![](media/image13.png){width="6.270833333333333in"
height="1.7732633420822397in"}

**\< FaceNet Process Structure \>**

얼굴 인식을 실행하기 전에 얼굴 감지가 우선시 되어야 하는데 우리는
MTCNN모델을 사용해 얼굴 감지기를 만든 다음 FaceNet 모델을 사용하여
감지된 각 얼굴에 대한 임베딩을 생성한 다음 얼굴의 정체성을 예측하는 SVM
분류기 모델을 사용한다.

Triplet Loss는 한 사람과 다른 모든 얼굴쌍에 대해 비교하고 margin을
강화한다. 특히, Embedding을 이용해 이미지의 좋은 품질의 특성을 추출해
고차원에서 저차원으로 변환하고, 이를 통해 기준 얼굴에 대한 같은 얼굴,
다른 얼굴 과의 유사성을 비교한다.

![](media/image14.png){width="4.404516622922134in"
height="1.163319116360455in"}

**\<Triplet loss\>**

![](media/image15.png){width="4.328125546806649in"
height="0.8085509623797026in"}

**\<Model structure\>**

이 기술에 있어 우리 팀은 FaceNet을 이용한 건물 출입에 대한 보안에
적용하고자 한다

![](media/image16.png){width="6.267716535433071in" height="2.125in"}

**2.2.3 deep sort를 이용한 동선 파악**

**SORT** = 디텍터 + 칼만필터 + 헝가리안 알고리즘,

**DeepSort** = 딥러닝 + SORT의 뜻을 내포하고 있으며, 프로젝트 내에서는
yolov5를 디텍터로 하여 딥소트 알고리즘을 구현하였다.

**2.2.3.1 Kalman Filter**

칼만 필터는 기존 추적하던 물체의 속도를 반영해서 다음 상황을 예측한다.
칼만 필터는 베이지안 추정과 같이 직접확률을 계산할 수 없는 경우 관련 된
값을 이용하여 원래 값을 구하는 것으로 예측과 갱신의 순환으로 이루어져
있다.

![](media/image17.png){width="4.59375in" height="2.6666666666666665in"}

측정값을 그냥 사용하면 되는 것 처럼 생각할 수 있지만, 노이즈가 추가되면
측정값을 100% 신뢰할 수 없다. 칼만필터는 기본적으로 가우시안 분포로 값이
분포되어 있다고 가정하고 있으며, 측정값의 분포가 가우시안이 아닐
경우에는 해당 분포에 맞는 변형된 칼만 알고리즘을 사용해야 한다.

**2.2.3.2 DeepSORT**

DeepSORT는 기존에 있던 SORT 알고리즘에 딥러닝 피쳐를 반영한 것이 가장 큰
차이점이라고 할 수 있다.

SORT는 칼만필터와 헝가리안 알고리즘으로 이루어져 있다. 헝가리안
알고리즘은 최저비용의 할당을 하려고 하는 최적화 문제를 해결하기 위한
알고리즘이다.

deep sort는 디텍터로 person detection을 수행한 뒤, 각 person의 정보, 즉
위치, 속도, deep learning feautre(person re-id)와 같은 정보들을 조합하여
헝가리안 알고리즘을 수행한다. deep learning feature와 칼만필터의 정보를
동시에 사용하므로 움직임에 대해서도, 이미지 특징에 대해서도 비교를 하기
때문에 트래킹을 지속적으로 강건하게 할 수 있다는 장점이 있다.

**2.2.3.3 Non Maxminum Supperssions**

NMS는 여러개의 바운딩 박스가 겹쳐있을 때 어떤 것을 선택하고 어떤 것을
버릴지 판단하는 알고리즘이다. 모든 바운딩 박스에 대해, 가장 높은
confidence score를 가진 박스를 선택하고, 해당 박스와의 IOU가 threshold
이상이면 제외 해준다,. 딥소트에서 YOLO3가 디텍팅한 바운딩 박스들을
트래커로 넘기기전 프리프로세싱 용으로 사용하고 있다.

**2.2.3.4 MARS: re-id dataset**

딥소트에서는 이전의 트래킹 결과와 현재 디텍팅 결과의 바운딩 박스들을
매칭하는데 헝가리안 알고리즘을 사용한다, 이 때 사용되는 최적화 팩터는
3가지인데 KNN, 딥러닝 피쳐 그리고 IOU 이다. 여기서 딥러닝 피쳐는 바운딩
박스내의 이미지간 유사도를 나타내며, 해당 모델을 학습시킬 때 사용되는
데이터셋은 Market1501 과 MARS 가 있다. 둘다 re-id 를 위해서 만들어진
데이터 셋이며 특히 MARS 는 비디오와 같은 타임시리즈 데이터에 특화시켜
Market1501을 확장한 버전이라고 보면 된다.

![](media/image18.png){width="3.4114588801399823in"
height="1.7680643044619422in"}

**\<deep sort 결과 예시\>**

**2.2.3.5 DeepSORT + Hist compareHist (Histogram matching)을 이용한 인물
식별 시도**

사람의 인상 착의에 대한 색분포를 비교하는 방법이며, color mapping, color
transfer라고도 한다.

MeanShift, CamShift 등의 기법에서 아이디어를 얻어, DeepSORT와 CCTV를
이용한 인물식별과 이를 이용하여 건물지도에 인물 위치정보를 맵핑을
시도하였으나, DeepSORT를 이용한 바운딩 박스에서는 배경이 반 이상을
차지하여, 이미지 간의 유사도에 오차가 크게 발생하였고, 히스토그램 비교
측정의 대표적인 방법(인터섹션, 카이제곱, 상관관계, 바타챠르야 측정)등이
있으나, 인터섹션과 카이제곱은 값 범위가 너무 크며, 절대값이 존재하지
않아, 각 측정 방법의 기준 threshold를 설정하는데 난관이 있었다.

![](media/image19.png){width="6.267716535433071in"
height="3.1805555555555554in"}

배경 색으로 인한 오차범위를 줄이기 위해 DeepSORT 바운딩 박스를
강제적으로 줄여주고, Slide Window 기법을 도입하여 많은 이미지 비교를
통해 기능을 구현하였다.

**2.2.4 통합 구현**

facenet, 이상상황 파악, deep sort 까지 활용하여 건물 출입을 관리하고,
건물 내 이상상황이나 사람들 간의 동선을 한눈에 파악할 수 있게 하는 map
GUI를 구현한다.

map에는 사람들의 이동 동선 및 이상상황에 대한 모니터링 기능이 있다.

CCTV 파일로부터 이동 동선을 산출해내는 공식은 다음과 같다

![](media/image20.png){width="3.7083333333333335in"
height="2.0208333333333335in"}

일자 복도도 CCTV 영상 속에선 뒤로 갈수록 좁아지는 모양이 나타나므로 각
꼭짓점에 대해 영상과 GUI에서 좌표를 각각 추출해내야 한다. 일단 점선을
기준으로 두 파트로 나눈 뒤 영상 이미지에서 각 변에 대한 직선의 방정식을
구해 GUI의 좌표와 1:1 매핑이 되는 일반식을 도출해 낸다.

위와 같은 과정을 거쳐 만들어진 map의 구성은 다음과 같다

![](media/image21.png){width="2.1317661854768155in"
height="1.6845428696412947in"}

\<figure .map GUI configuration\>

기역자 형태의 복도를 가정했으며, 각 복도의 끝에 cctv가 달려있음을
가정하였다. GUI 지도에 CCTV로 탐지된 사람들의 좌표를 이용해서 지도
좌표로 매핑해 표시한다. 이 때 탐지된 인원 수를 나타낸다. 또한 이상 상황
발생 시 지도에 발생 표시를 한다

이상 상황에는 Fainting(기절), Violence(폭력) 상황이 있고 구별된 표시를
할 수 있다. 또한 이상 상황이 발생한 위치를 지도 내에 표시해 신속한
대처를 할 수 있다,

![](media/image22.png){width="2.2708333333333335in"
height="1.9479166666666667in"}

그리고 'ㄱ'자 형 복도에 CCTV 2개를 이용하기 때문에 동시에 탐지되는
사람이 있을 것이다. Deep Sort를 이용해 사람을 구별할 수 있도록 하여 두
CCTV에 한 사람이 동시에 탐지되더라도 지도에 하나로 표시가 가능하고,
구별된 사람의 Name을 지도 내에 표시한다.

![](media/image23.png){width="6.268055555555556in"
height="3.7916666666666665in"}

\<인물 식별 과정 CY = 찬영, DB = 다빈\>

**3 결론**

**3.1 기대효과**

재난 상황 시 사람의 위치를 직관적으로 파악하여 구조 작업의 효율을 높여
인명구조에 도움을 줄 수 있다. 재난 상황에서 건물 내 인원수 및 위치
파악은 매우 중요한 부분이다. 로그 파일을 실시간으로 외부 서버에
저장하고, 재난 상황시 이를 자유롭게 사용할 수 있게 만드는 시스템을
구축한다면 구조대가 건물내 인원 수 및 동선을 파악하는데 크게 도움이 되고
이는 구조 작업의 성공에도 많은 영향을 줄것이다.

또한 언택트 시대에 따라 비접촉 방식의 기술이 많이 필요한데 출입 명부를
관리할 때 FaceNet을 사용하면 더 효과적일 것이라고 기대된다. 감염자
발생시 동선 저장 기능을 통해 보다 효율적으로 접촉자 분류가 가능하고
전염병 확산 억제에 도움을 줄 수 있을것이다

마지막으로 응급 상황이나 범죄 상황에 대한 자동 인식 수요가 증가하고
있다. 본 프로젝트에서 실신, 폭력상황을 감지할 수 있는 CCTV는 공공기관,
병원, 공항 등 사람이 많이 다니면서 앞서 말한 상황에 대해 빠른 대처가
필요한 곳에서 사용될 수 있을것이다. 이상상황이 일어날경우 관리자에게
알림을 주고, 로그를 저장하여 차후 대응에 활용할 수 있다.

**3.2 한계점 및 발전 방향**

![](media/image24.png){width="6.268055555555556in"
height="4.0472222222222225in"}

**4 조원 소개**

![](media/image25.png){width="6.114583333333333in"
height="5.041666666666667in"}

**5 참고 문헌**

![](media/image26.png){width="6.268055555555556in"
height="0.7972222222222223in"}
